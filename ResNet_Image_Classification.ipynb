{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLfrPBmiQNQn",
        "outputId": "e2855d25-1201-4e1b-f5f0-f92da1378937"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PBAB1HlFPt2E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
        "import albumentations\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torchvision import datasets, models, transforms\n",
        "import os.path as osp\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6fB1WqJP2Kh",
        "outputId": "b09ce426-b1c3-4aaf-e008-334290ff5fd6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "data_path = \"/content/gdrive/My Drive/data/insect_1_split\""
      ],
      "metadata": {
        "id": "M7-BcBWZRc3F"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MODEL(nn.Module):\n",
        "    def __init__(self, model_name=\"resnet50d\", out_features=12, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9Pq45hpWRvZc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricMonitor:\n",
        "    def __init__(self, float_precision=5):\n",
        "        self.float_precision = float_precision\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
        "\n",
        "    def update(self, metric_name, val):\n",
        "        metric = self.metrics[metric_name]\n",
        "\n",
        "        metric[\"val\"] += val\n",
        "        metric[\"count\"] += 1\n",
        "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \" | \".join(\n",
        "            [\n",
        "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
        "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
        "                )\n",
        "                for (metric_name, metric) in self.metrics.items()\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "iR4so0ENSWDZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_macro(output, target):\n",
        "    y_pred = torch.softmax(output, dim=1)\n",
        "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
        "    target = target.cpu()\n",
        "\n",
        "    return f1_score(target, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "R0VjrYBPSo7T"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recall_macro(output, target):\n",
        "    y_pred = torch.softmax(output, dim=1)\n",
        "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
        "    target = target.cpu()\n",
        "    # tp fn fp\n",
        "    return recall_score(target, y_pred, average=\"macro\", zero_division=0)"
      ],
      "metadata": {
        "id": "VTvIZ64lSpVA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_learning_rate(epoch, init_lr, n_epochs, batch=0, nBatch=None, lr_schedule_type='cosine'):\n",
        "    if lr_schedule_type == 'cosine':\n",
        "        t_total = n_epochs * nBatch\n",
        "        t_cur = epoch * nBatch + batch\n",
        "        lr = 0.5 * init_lr * (1 + math.cos(math.pi * t_cur / t_total))\n",
        "    elif lr_schedule_type is None:\n",
        "        lr = init_lr\n",
        "    else:\n",
        "        raise ValueError('do not support: %s' % lr_schedule_type)\n",
        "    return lr\n"
      ],
      "metadata": {
        "id": "TCQPcyjUTQ0W"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, batch=0, nBatch=None):\n",
        "    \"\"\" adjust learning of a given optimizer and return the new learning rate \"\"\"\n",
        "    new_lr = calc_learning_rate(epoch, lr, epoches, batch, nBatch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "    return new_lr"
      ],
      "metadata": {
        "id": "i2q5m8jhTMMc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target):\n",
        "    y_pred = torch.softmax(output, dim=1)\n",
        "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
        "    target = target.cpu()\n",
        "\n",
        "    return accuracy_score(target, y_pred)"
      ],
      "metadata": {
        "id": "iT-Nf0GhTem-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_torch_transforms(img_size=224):\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(p=0.2),\n",
        "            transforms.RandomRotation((-5, 5)),\n",
        "            transforms.RandomAutocontrast(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "    return data_transforms"
      ],
      "metadata": {
        "id": "Mw6xpkH2UNF4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    metric_monitor = MetricMonitor()\n",
        "    model.train()\n",
        "    nBatch = len(train_loader)\n",
        "    stream = tqdm(train_loader)\n",
        "    for i, (images, target) in enumerate(stream, start=1):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "        output = model(images)\n",
        "        loss = criterion(output, target.long())\n",
        "        f1_macro = calculate_f1_macro(output, target)\n",
        "        recall_macro = calculate_recall_macro(output, target)\n",
        "        acc = accuracy(output, target)\n",
        "        metric_monitor.update('Loss', loss.item())\n",
        "        metric_monitor.update('F1', f1_macro)\n",
        "        metric_monitor.update('Recall', recall_macro)\n",
        "        metric_monitor.update('Accuracy', acc)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr = adjust_learning_rate(optimizer, epoch, i, nBatch)\n",
        "        stream.set_description(\n",
        "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(\n",
        "                epoch=epoch,\n",
        "                metric_monitor=metric_monitor)\n",
        "        )\n",
        "    return metric_monitor.metrics['Accuracy'][\"avg\"], metric_monitor.metrics['Loss'][\"avg\"]"
      ],
      "metadata": {
        "id": "6X9zQDlRSD9B"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion, epoch):\n",
        "    metric_monitor = MetricMonitor()\n",
        "    model.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(stream, start=1):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target.long())\n",
        "            f1_macro = calculate_f1_macro(output, target)\n",
        "            recall_macro = calculate_recall_macro(output, target)\n",
        "            acc = accuracy(output, target)\n",
        "            metric_monitor.update('Loss', loss.item())\n",
        "            metric_monitor.update('F1', f1_macro)\n",
        "            metric_monitor.update(\"Recall\", recall_macro)\n",
        "            metric_monitor.update('Accuracy', acc)\n",
        "            stream.set_description(\n",
        "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(\n",
        "                    epoch=epoch,\n",
        "                    metric_monitor=metric_monitor)\n",
        "            )\n",
        "    return metric_monitor.metrics['Accuracy'][\"avg\"], metric_monitor.metrics['Loss'][\"avg\"]"
      ],
      "metadata": {
        "id": "xfbYVu5lTiDz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epoches = 10\n",
        "image_size = 224\n",
        "batch_size = 4\n",
        "model_name = 'resnet50d'\n",
        "train_path = osp.join(data_path, \"train\")\n",
        "val_path = osp.join(data_path, \"val\")\n",
        "save_path = \"/content/gdrive/My Drive/data/checkpoints\"\n",
        "num_classes = len(os.listdir(osp.join(data_path, \"train\"))),\n",
        "weight_decay = 1e-5"
      ],
      "metadata": {
        "id": "Qb94W25UVEX8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "losss = []\n",
        "val_accs = []\n",
        "val_losss = []\n",
        "data_transforms = get_torch_transforms(image_size)\n",
        "train_transforms = data_transforms['train']\n",
        "valid_transforms = data_transforms['val']\n",
        "train_dataset = datasets.ImageFolder(train_path, train_transforms)\n",
        "valid_dataset = datasets.ImageFolder(val_path, valid_transforms)\n",
        "model_path = osp.join(save_path, model_name+\"_pretrained_\" + str(image_size))\n",
        "if not osp.isdir(model_path):\n",
        "  os.makedirs(model_path)\n",
        "  print(\"save dir {} created\".format(model_path))\n",
        "train_loader = DataLoader(\n",
        "  train_dataset, batch_size=batch_size, shuffle=True,\n",
        "  num_workers=0, pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "  valid_dataset, batch_size=batch_size, shuffle=False,\n",
        "  num_workers=0, pin_memory=True,\n",
        ")\n",
        "print(train_dataset.classes)\n",
        "model = MODEL()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, epoches + 1):\n",
        "  acc, loss = train(train_loader, model, criterion, optimizer, epoch)\n",
        "  val_acc, val_loss = validate(val_loader, model, criterion, epoch)\n",
        "  accs.append(acc)\n",
        "  losss.append(loss)\n",
        "  val_accs.append(val_acc)\n",
        "  val_losss.append(val_loss)\n",
        "  if val_acc >= best_acc:\n",
        "    save_path = osp.join(model_path, f\"{model}_{epoch}epochs_accuracy{acc:.5f}_weights.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    best_acc = val_acc"
      ],
      "metadata": {
        "id": "ze1jicq_Z2c5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
